{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "classifier.add(Flatten())\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1200 images belonging to 2 classes.\n",
      "Found 400 images belonging to 2 classes.\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Niraj\\.conda\\envs\\tensorflow_env\\lib\\site-packages\\ipykernel_launcher.py:27: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "C:\\Users\\Niraj\\.conda\\envs\\tensorflow_env\\lib\\site-packages\\ipykernel_launcher.py:27: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., validation_data=<keras.pre..., steps_per_epoch=25, epochs=20, validation_steps=20)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 16s 625ms/step - loss: 0.1596 - accuracy: 0.9528 - val_loss: 0.2667 - val_accuracy: 0.8686\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 14s 545ms/step - loss: 0.1720 - accuracy: 0.9260 - val_loss: 0.4823 - val_accuracy: 0.8816\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 11s 437ms/step - loss: 0.1881 - accuracy: 0.9212 - val_loss: 0.2491 - val_accuracy: 0.8894\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 17s 674ms/step - loss: 0.2204 - accuracy: 0.9075 - val_loss: 0.1933 - val_accuracy: 0.8931\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 12s 465ms/step - loss: 0.1797 - accuracy: 0.9401 - val_loss: 0.2725 - val_accuracy: 0.8702\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 14s 542ms/step - loss: 0.1411 - accuracy: 0.9426 - val_loss: 0.2124 - val_accuracy: 0.8849\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 15s 583ms/step - loss: 0.2240 - accuracy: 0.9056 - val_loss: 0.2238 - val_accuracy: 0.9119\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 14s 558ms/step - loss: 0.1509 - accuracy: 0.9450 - val_loss: 0.3238 - val_accuracy: 0.8701\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 12s 469ms/step - loss: 0.1208 - accuracy: 0.9617 - val_loss: 0.1361 - val_accuracy: 0.8686\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 16s 652ms/step - loss: 0.1235 - accuracy: 0.9503 - val_loss: 0.5603 - val_accuracy: 0.8997\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 12s 478ms/step - loss: 0.1670 - accuracy: 0.9298 - val_loss: 0.2723 - val_accuracy: 0.9022\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 14s 543ms/step - loss: 0.1538 - accuracy: 0.9362 - val_loss: 0.1127 - val_accuracy: 0.9178\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 15s 597ms/step - loss: 0.1264 - accuracy: 0.9528 - val_loss: 0.0536 - val_accuracy: 0.9211\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 13s 503ms/step - loss: 0.1192 - accuracy: 0.9488 - val_loss: 0.1155 - val_accuracy: 0.9022\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 16s 636ms/step - loss: 0.1285 - accuracy: 0.9426 - val_loss: 0.2341 - val_accuracy: 0.8947\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 18s 721ms/step - loss: 0.1370 - accuracy: 0.9515 - val_loss: 0.1177 - val_accuracy: 0.9038\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 21s 841ms/step - loss: 0.1192 - accuracy: 0.9550 - val_loss: 0.0938 - val_accuracy: 0.9243\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 15s 601ms/step - loss: 0.0822 - accuracy: 0.9694 - val_loss: 0.1219 - val_accuracy: 0.9119\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 19s 771ms/step - loss: 0.0873 - accuracy: 0.9688 - val_loss: 0.4659 - val_accuracy: 0.8355\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 15s 616ms/step - loss: 0.0716 - accuracy: 0.9758 - val_loss: 0.2242 - val_accuracy: 0.9263\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2887a598f28>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('C:/Users/Niraj\\Desktop/just like that/inGenius/trin_cnn',\n",
    "                                                 target_size=(64, 64),\n",
    "                                                 batch_size=32,\n",
    "                                                 class_mode='binary')\n",
    "test_set = test_datagen.flow_from_directory('C:/Users/Niraj/Desktop/just like that/inGenius/test_cnn',\n",
    "                                            target_size=(64, 64),\n",
    "                                            batch_size=32,\n",
    "                                            class_mode='binary')\n",
    "#print(test_set)\n",
    "\n",
    "classifier.fit_generator(training_set,\n",
    "                        samples_per_epoch=800,\n",
    "                        nb_epoch=20,\n",
    "                        validation_data=test_set,\n",
    "                        nb_val_samples=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hppy\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('C:/Users/Niraj/Desktop/just like that/inGenius/spec/56.png', target_size=(64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = classifier.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0] == 1: \n",
    "    prediction = 'hppy'\n",
    "else:\n",
    "    prediction = 'fer'\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sounddevice\n",
      "  Downloading sounddevice-0.4.1-py3.cp32.cp33.cp34.cp35.cp36.cp37.cp38.cp39.pp32.pp33.pp34.pp35.pp36.pp37-none-win_amd64.whl (167 kB)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\niraj\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from sounddevice) (1.14.3)\n",
      "Requirement already satisfied: pycparser in c:\\users\\niraj\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from CFFI>=1.0->sounddevice) (2.20)\n",
      "Installing collected packages: sounddevice\n",
      "Successfully installed sounddevice-0.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sounddevice --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
